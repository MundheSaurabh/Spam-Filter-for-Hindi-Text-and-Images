{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"UhWhntSWMwps","executionInfo":{"status":"error","timestamp":1688026206380,"user_tz":-330,"elapsed":3667,"user":{"displayName":"saurabh mundhe","userId":"02022963081882294272"}},"outputId":"2f3dbc37-3397-430c-bb0f-7ae8162fbc9f","colab":{"base_uri":"https://localhost:8080/","height":428}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-1-906be34eedd1>:5: DeprecationWarning: Please use `rank_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n","  from scipy.ndimage.filters import rank_filter\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-906be34eedd1>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrank_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytesseract\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage_to_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytesseract'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import tensorflow as tf\n","import numpy as np\n","import cv2\n","from PIL import Image,ImageDraw\n","from scipy.ndimage.filters import rank_filter\n","import sys,argparse\n","from pytesseract import image_to_string\n","import pandas as pd\n","import re\n","import pickle\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.svm import SVC,NuSVC\n","from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_m-TXk67Mwpu"},"outputs":[],"source":["def image_spam_score(image,model):\n","    image_data = tf.gfile.FastGFile(image,'rb').read()\n","\n","    with tf.gfile.FastGFile(model,'rb') as f:\n","        graph_def = tf.GraphDef()\n","        graph_def.ParseFromString(f.read())\n","        tf.import_graph_def(graph_def,name='')\n","\n","    with tf.Session() as sees:\n","        softmax_tensor = sees.graph.get_tensor_by_name('final_result:0')\n","        predictions = sees.run(softmax_tensor,{'DecodeJpeg/contents:0':image_data})\n","\n","    ham = predictions[0][0] * 100\n","    spam = predictions[0][1] * 100\n","    return ham,spam\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RKMJvUATMwpv"},"outputs":[],"source":["def intersect_crops(crop1, crop2):\n","    x11, y11, x21, y21 = crop1\n","    x12, y12, x22, y22 = crop2\n","    return max(x11, x12), max(y11, y12), min(x21, x22), min(y21, y22)\n","\n","def pad_crop(crop, contours, edges, border_contour, pad_px=15):\n","    \"\"\"Slightly expand the crop to get full contours.\n","    This will expand to include any contours it currently intersects, but will\n","    not expand past a border.\n","    \"\"\"\n","    bx1, by1, bx2, by2 = 0, 0, edges.shape[0], edges.shape[1]\n","    if border_contour is not None and len(border_contour) > 0:\n","        c = props_for_contours([border_contour], edges)[0]\n","        bx1, by1, bx2, by2 = c['x1'] + 5, c['y1'] + 5, c['x2'] - 5, c['y2'] - 5\n","\n","    def crop_in_border(crop):\n","        x1, y1, x2, y2 = crop\n","        x1 = max(x1 - pad_px, bx1)\n","        y1 = max(y1 - pad_px, by1)\n","        x2 = min(x2 + pad_px, bx2)\n","        y2 = min(y2 + pad_px, by2)\n","        return crop\n","\n","    crop = crop_in_border(crop)\n","\n","    c_info = props_for_contours(contours, edges)\n","    changed = False\n","    for c in c_info:\n","        this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n","        this_area = crop_area(this_crop)\n","        int_area = crop_area(intersect_crops(crop, this_crop))\n","        new_crop = crop_in_border(union_crops(crop, this_crop))\n","        if 0 < int_area < this_area and crop != new_crop:\n","            print ('%s -> %s' % (str(crop), str(new_crop)))\n","            changed = True\n","            crop = new_crop\n","\n","    if changed:\n","        return pad_crop(crop, contours, edges, border_contour, pad_px)\n","    else:\n","        return crop\n","\n","def union_crops(crop1, crop2):\n","    \"\"\"Union two (x1, y1, x2, y2) rects.\"\"\"\n","    x11, y11, x21, y21 = crop1\n","    x12, y12, x22, y22 = crop2\n","    return min(x11, x12), min(y11, y12), max(x21, x22), max(y21, y22)\n","\n","\n","def crop_area(crop):\n","    x1, y1, x2, y2 = crop\n","    return max(0, x2 - x1) * max(0, y2 - y1)\n","\n","\n","def props_for_contours(contours, ary):\n","    \"\"\"Calculate bounding box & the number of set pixels for each contour.\"\"\"\n","    c_info = []\n","    for c in contours:\n","        x,y,w,h = cv2.boundingRect(c)\n","        c_im = np.zeros(ary.shape)\n","        cv2.drawContours(c_im, [c], 0, 255, -1)\n","        c_info.append({\n","            'x1': x,\n","            'y1': y,\n","            'x2': x + w - 1,\n","            'y2': y + h - 1,\n","            'sum': np.sum(ary * (c_im > 0))/255\n","        })\n","    return c_info\n","\n","\n","def find_optimal_components_subset(contours, edges):\n","    \"\"\"Find a crop which strikes a good balance of coverage/compactness.\n","    Returns an (x1, y1, x2, y2) tuple.\n","    \"\"\"\n","    c_info = props_for_contours(contours, edges)\n","    c_info.sort(key=lambda x: -x['sum'])\n","    total = np.sum(edges) / 255\n","    area = edges.shape[0] * edges.shape[1]\n","\n","    c = c_info[0]\n","    del c_info[0]\n","    this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n","    crop = this_crop\n","    covered_sum = c['sum']\n","\n","    while covered_sum < total:\n","        changed = False\n","        recall = 1.0 * covered_sum / total\n","        prec = 1 - 1.0 * crop_area(crop) / area\n","        f1 = 2 * (prec * recall / (prec + recall))\n","        #print '----'\n","        for i, c in enumerate(c_info):\n","            this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n","            new_crop = union_crops(crop, this_crop)\n","            new_sum = covered_sum + c['sum']\n","            new_recall = 1.0 * new_sum / total\n","            new_prec = 1 - 1.0 * crop_area(new_crop) / area\n","            new_f1 = 2 * new_prec * new_recall / (new_prec + new_recall)\n","\n","            # Add this crop if it improves f1 score,\n","            # _or_ it adds 25% of the remaining pixels for <15% crop expansion.\n","            # ^^^ very ad-hoc! make this smoother\n","            remaining_frac = c['sum'] / (total - covered_sum)\n","            new_area_frac = 1.0 * crop_area(new_crop) / crop_area(crop) - 1\n","            if new_f1 > f1 or (\n","                    remaining_frac > 0.25 and new_area_frac < 0.15):\n","                print ('%d %s -> %s / %s (%s), %s -> %s / %s (%s), %s -> %s' % (\n","                        i, covered_sum, new_sum, total, remaining_frac,\n","                        crop_area(crop), crop_area(new_crop), area, new_area_frac,\n","                        f1, new_f1))\n","                crop = new_crop\n","                covered_sum = new_sum\n","                del c_info[i]\n","                changed = True\n","                break\n","\n","        if not changed:\n","            break\n","\n","    return crop\n","\n","\n","def dilate(ary, N, iterations):\n","    \"\"\"Dilate using an NxN '+' sign shape. ary is np.uint8.\"\"\"\n","    kernel = np.ones((N,N), dtype=np.uint8)\n","    kernel[(N-1)//2,:] = 1\n","    dilated_image = cv2.dilate(ary / 255, kernel, iterations=iterations)\n","\n","    kernel = np.ones((N,N), dtype=np.uint8)\n","    kernel[:,(N-1)//2] = 1\n","    dilated_image = cv2.dilate(dilated_image, kernel, iterations=iterations)\n","    return dilated_image\n","\n","\n","def find_components(edges, max_components=16):\n","    \"\"\"Dilate the image until there are just a few connected components.\n","    Returns contours for these components.\"\"\"\n","    # Perform increasingly aggressive dilation until there are just a few\n","    # connected components.\n","    count = 21\n","    dilation = 5\n","    n = 1\n","    while count > 16:\n","        n += 1\n","        dilated_image = dilate(edges, N=3, iterations=n)\n","        dilated_image = dilated_image.astype(np.uint8)\n","        ret,contours, hierarchy = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","        count = len(contours)\n","    return contours\n","\n","\n","def angle_from_right(deg):\n","    return min(deg % 90, 90 - (deg % 90))\n","\n","def remove_border(contour, ary):\n","    \"\"\"Remove everything outside a border contour.\"\"\"\n","    # Use a rotated rectangle (should be a good approximation of a border).\n","    # If it's far from a right angle, it's probably two sides of a border and\n","    # we should use the bounding box instead.\n","    c_im = np.zeros(ary.shape)\n","    r = cv2.minAreaRect(contour)\n","    degs = r[2]\n","    if angle_from_right(degs) <= 10.0:\n","        box = cv2.boxPoints(r)\n","        box = np.int0(box)\n","        cv2.drawContours(c_im, [box], 0, 255, -1)\n","        cv2.drawContours(c_im, [box], 0, 0, 4)\n","    else:\n","        x1, y1, x2, y2 = cv2.boundingRect(contour)\n","        cv2.rectangle(c_im, (x1, y1), (x2, y2), 255, -1)\n","        cv2.rectangle(c_im, (x1, y1), (x2, y2), 0, 4)\n","\n","    return np.minimum(c_im, ary)\n","\n","\n","def find_border_components(contours,ary):\n","    borders = []\n","    area = ary.shape[0] * ary.shape[1]\n","    for i,c in enumerate(contours):\n","        x,y,w,h = cv2.boundingRect(c)\n","        if w*h > 0.5 * area:\n","            borders.append((i,x,y,x+w-1,y+h-1))\n","    return borders\n","\n","\n","def downscale(im,max_dim=1024):\n","    a,b = im.size\n","    if max(a,b) <= max_dim:\n","        return 1.0,im\n","    scale = 1.0 * max_dim / max(a,b)\n","    new_image = im.resize((int(scale*a),int(scale*b)),Image.ANTIALIAS)\n","    return scale,new_image\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZmkG60BMwpw"},"outputs":[],"source":["def crop_text_from_image(image):\n","    image = Image.open(image)\n","\n","    scale,new_image = downscale(image)\n","    edges = cv2.Canny(np.asarray(new_image),100,200)\n","    ret,contours,hierarchy = cv2.findContours(edges,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n","    borders = find_border_components(contours,edges)\n","    borders.sort(key=lambda i_x1_y1_x2_y2: (i_x1_y1_x2_y2[3] - i_x1_y1_x2_y2[1]) * (i_x1_y1_x2_y2[4] - i_x1_y1_x2_y2[2]))\n","    border_contour = None\n","    if len(borders):\n","        border_contour = contours[borders[0][0]]\n","        edges = remove_border(border_contour, edges)\n","\n","    edges = 255 * (edges > 0).astype(np.uint8)\n","    maxed_rows = rank_filter(edges, -4, size=(1, 20))\n","    maxed_cols = rank_filter(edges, -4, size=(20, 1))\n","    debordered = np.minimum(np.minimum(edges, maxed_rows), maxed_cols)\n","    edges = debordered\n","\n","    contours = find_components(edges)\n","    if len(contours) == 0:\n","        print ('%s -> (no text!)' % path)\n","        return image\n","\n","    crop = find_optimal_components_subset(contours, edges)\n","    crop = pad_crop(crop, contours, edges, border_contour)\n","    crop = [int(x / scale) for x in crop]\n","\n","    text_im = image.crop(crop).convert('RGB')\n","    return text_im"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgycNijjMwpx"},"outputs":[],"source":["def text_image_processing(text_image):#PIL image is taken as input\n","    image = np.array(text_image)\n","    image = image[:,:,::-1] #Converting RGB to BGR\n","    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","    gray = cv2.bilateralFilter(gray,3,21,21)\n","    return gray\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4dgLBNGgMwpx"},"outputs":[],"source":["def rem_stopwords(text):\n","    stopwords = open(\"/home/pallav/Desktop/hindi-tokenizer-master/stopwords.txt\",\"r\",encoding=\"utf8\")\n","    stwords=stopwords.read()\n","\n","    words = re.sub('\\n',' ',stwords)\n","    word = words.split()\n","    clearW = [wor for wor in text if wor not in word]\n","    return clearW"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_Q9YzUuMwpx"},"outputs":[],"source":["def hi_stem(lst):\n","\n","    suffixes = {\n","    1: [\"ो\", \"े\", \"ू\", \"ु\", \"ी\", \"ि\", \"ा\"],\n","    2: [\"कर\", \"ाओ\", \"िए\", \"ाई\", \"ाए\", \"ने\", \"नी\", \"ना\", \"ते\", \"ीं\", \"ती\", \"ता\", \"ाँ\", \"ां\", \"ों\", \"ें\",\"ाना\",\n","        \"ाऊ\",\"लु\",\"ाव\",\"ीय\",\"हट\"],\n","    3: [\"ाकर\", \"ाइए\", \"ाईं\", \"ाया\", \"ेगी\", \"ेगा\", \"ोगी\", \"ोगे\", \"ाने\", \"ाना\", \"ाते\", \"ाती\", \"ाता\", \"तीं\", \"ाओं\",\n","        \"ाएं\", \"ुओं\", \"ुएं\", \"ुआं\",\"दार\",\"िया\",\"हार\",\"ावट\",\"ोला\",\"कार\",\"ान\",\"ौटी\",\"ैया\",\"ेरा\",\"ोड़ा\"],\n","    4: [\"ाएगी\", \"ाएगा\", \"ाओगी\", \"ाओगे\", \"एंगी\", \"ेंगी\", \"एंगे\", \"ेंगे\", \"ूंगी\", \"ूंगा\", \"ातीं\", \"नाओं\", \"नाएं\", \"ताओं\",\n","        \"ताएं\", \"ियाँ\", \"ियों\", \"ियां\",\"वाला\",\"िक\"],\n","    5: [\"ाएंगी\", \"ाएंगे\", \"ाऊंगी\", \"ाऊंगा\", \"ाइयाँ\", \"ाइयों\", \"ाइयां\",\"क्कड़\"]\n","    }\n","\n","\n","    txt = []\n","    for word in lst:\n","        for L in 5, 4, 3, 2, 1:\n","            if len(word) > L + 1:\n","                for suf in suffixes[L]:\n","                    if word.endswith(suf):\n","                        word = word[:-L]\n","        txt.append(word)\n","    return txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2uWzEzAqMwpy"},"outputs":[],"source":["def purify(doc):\n","    punctuations = '''!@#$£%^&*()\"':-+_=“”/?><|।.,\\{}[]'''\n","    digits = '''1234567890०१२३४५६७८९'''\n","    data_no_punc = \"\"\n","    for char in doc:\n","        if(char not in punctuations and char not in digits):\n","            data_no_punc = data_no_punc + char\n","    return data_no_punc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zE5hsQdfMwpy"},"outputs":[],"source":["def processed_text(text):\n","    no_punct = purify(text)\n","    no_stopwords = rem_stopwords(no_punct.split())\n","    stemmed = hi_stem(no_stopwords)\n","    return \" \".join(stemmed)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AOdP3VEwMwpz"},"outputs":[],"source":["def text_spam(text):\n","    raw_data = pd.read_excel(\"/home/pallav/Desktop/PROJECT/hindi_spam.xlsx\")\n","    E_mails = raw_data\n","    i=0\n","    for e in E_mails['text']:\n","        E_mails.text[i]=''.join(list(map(purify,e)))\n","        E_mails.text[i]=E_mails.text[i].split()\n","        i=i+1\n","\n","    E_mails['text']=list(map(rem_stopwords,E_mails['text']))\n","\n","    email = []\n","    email = (list(map(hi_stem,E_mails['text'])))\n","    E_mails['text'] = email\n","\n","    for  i in range(0,E_mails.shape[0]):\n","        E_mails['text'][i] = ' '.join(E_mails['text'][i])\n","\n","    transformer2 = TfidfVectorizer(ngram_range=(1,1))\n","    counts2 = transformer2.fit_transform(E_mails['text'])\n","\n","    NBModel = BernoulliNB().fit(counts2, E_mails['type'])\n","    SVCModel = SVC(kernel='linear').fit(counts2,E_mails['type'])\n","    NuSVCModel = NuSVC(kernel='linear').fit(counts2,E_mails['type'])\n","    RFModel = RandomForestClassifier(n_estimators=50,min_samples_split=3).fit(counts2,E_mails['type'])\n","    GBModel = GradientBoostingClassifier(n_estimators=50,min_samples_split=200).fit(counts2,E_mails['type'])\n","\n","    counts1 = transformer2.transform([text])\n","\n","    NBpred = NBModel.predict(counts1)\n","    SVCpred = SVCModel.predict(counts1)\n","    NuSVCpred = NuSVCModel.predict(counts1)\n","    RFpred = RFModel.predict(counts1)\n","    GBpred = GBModel.predict(counts1)\n","\n","    pred_list = [NBpred,SVCpred,NuSVCpred,RFpred,GBpred]\n","    pred = max(pred_list,key=pred_list.count)\n","\n","\n","    return pred[0]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"An9e_dw3Mwpz"},"outputs":[],"source":["def image_classification(image,model):\n","    ham,spam = image_spam_score(image,model)\n","    img = Image.open(image).convert('RGB')\n","    cv_image = np.array(img)\n","    cv_image = cv_image[:,:,::-1]\n","\n","\n","\n","    if spam > 80:\n","        cv2.imwrite(os.path.join('/home/pallav/Desktop/PROJECT/mails/spam/images/',\"spam.png\"),cv_image)\n","        print(\"SPAM!!!!\")\n","\n","    else:\n","        text_image = crop_text_from_image(image)\n","        text_image = text_image_processing(text_image)\n","        text = image_to_string(text_image,lang='hin')\n","        text = processed_text(text)\n","        pred = text_spam(text)\n","\n","        if pred == 'spam':\n","            cv2.imwrite(os.path.join('/home/pallav/Desktop/PROJECT/mails/spam/images/','spam.png'),cv_image)\n","            print(\"SPAM!!!!!\")\n","        else:\n","            cv2.imwrite(os.path.join('/home/pallav/Desktop/PROJECT/mails/ham/images/',\"ham.png\"),cv_image)\n","            print(\"HAM!!!!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkpOxd82Mwpz"},"outputs":[],"source":["def text_classification(text):\n","#     with open(text,'r') as f:\n","#         text = f.read()\n","    text1 = processed_text(text)\n","    pred = text_spam(text1)\n","    if pred == 'spam':\n","        with open(os.path.join('/home/pallav/Desktop/PROJECT/mails/spam/text/','spam.txt'),'w') as f:\n","            f.write(text)\n","        print(\"SPAM!!!\")\n","    else:\n","        with open(os.path.join('/home/pallav/Desktop/PROJECT/mails/ham/text/','ham.txt'),'w') as f:\n","            f.write(text)\n","        print(\"HAM!!!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cjIR_f55Mwpz","outputId":"1ae7a3bc-e150-4119-bda5-44183be82422"},"outputs":[{"name":"stderr","output_type":"stream","text":["usage: ipykernel_launcher.py [-h] [-i IMAGE] [-m MODEL] [-t TEXT]\n","ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-3d58ec0f-04e4-4676-939a-011757a997a9.json\n"]},{"ename":"SystemExit","evalue":"2","output_type":"error","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"name":"stderr","output_type":"stream","text":["/home/pallav/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}],"source":["if __name__ == '__main__':\n","    ap = argparse.ArgumentParser()\n","    ap.add_argument('-i','--image',required = False,help = \"Path to the image\")\n","    ap.add_argument('-m','--model',required = False,help = \"path to the model\")\n","    ap.add_argument('-t','--text',required = False,help = \"Path to the text file\")\n","#     ap.add_argument('-s','--spam',required = True,help = \"Path to the Spam Directory\")\n","#     ap.add_argument('-ha','--ham',required = True,help = \"Path to the Ham directory\")\n","    args = vars(ap.parse_args())\n","\n","#     spam_path = args['spam']\n","#     ham_path = args['ham']\n","\n","    if args['text'] is not None:\n","        with open(args['text'],'r') as f:\n","            text = f.read()\n","        text_classification(text)\n","\n","    elif args['image'] is not None:\n","        im = args['image']\n","        model = args['model']\n","        image_classification(im,model)\n","    else:\n","        print(\"please provide proper arguments for help type -h or --help\")\n","\n",""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}